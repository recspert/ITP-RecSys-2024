{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up Colab environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "username = 'recspert'\n",
    "repo = 'ITP-RecSys-2024'\n",
    "\n",
    "# remove local directory if it already exists\n",
    "if os.path.isdir(repo):\n",
    "    !rm -rf {repo}\n",
    "\n",
    "!git clone https://github.com/{username}/{repo}.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing polara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --no-cache-dir --upgrade git+https://github.com/evfro/polara.git@develop#egg=polara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import diags, csr_matrix\n",
    "from scipy.sparse.linalg import norm as spnorm\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "from polara import get_movielens_data\n",
    "\n",
    "# navigating to cloned repo directory in Colab\n",
    "%cd {repo}\n",
    "from dataprep import transform_indices, leave_last_out, reindex_data\n",
    "from evaluation import topn_recommendations, model_evaluate, downvote_seen_items\n",
    "# restoring original location\n",
    "%cd -"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment description"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll split data into 3 parts - training, validation and test.\n",
    "- You will firstly use training and validation to tune your models and finding optimal configuration.\n",
    "- Once a set of optimal hyper-parameters is found, you'll need to recompute your models with it on the joint training+validation dataset and report final quality on the test data.\n",
    "\n",
    "For the test data you simply split one last item from each user. The remaining part goes into training+validation. Likewise, you split it one more time the same way as before to get our dataset for tuning.\n",
    "\n",
    "So the scheme is as follows:\n",
    "1. Tune on the training and evaluate on the validation data. Find optimal config.\n",
    "2. Retrain once on the trainin+validation with the optimal config. Report final quality using the test (holdout) data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepraring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_movielens_data(include_time=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final test data\n",
    "training_validation_, holdout_ = leave_last_out(data)\n",
    "# validation data\n",
    "training_, validation_ = leave_last_out(training_validation_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reindexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, data_index = transform_indices(training_, 'userid', 'movieid')\n",
    "# split validation data\n",
    "validation = reindex_data(validation_, data_index, filter_invalid=True)\n",
    "validation = validation.sort_values('userid')\n",
    "# split final test data\n",
    "holdout = reindex_data(holdout_, data_index, filter_invalid=True)\n",
    "holdout = holdout.sort_values('userid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_description = dict(\n",
    "    users = data_index['users'].name,\n",
    "    items = data_index['items'].name,\n",
    "    feedback = 'rating',\n",
    "    n_users = len(data_index['users']),\n",
    "    n_items = len(data_index['items']),\n",
    "    test_users = validation[data_index['users'].name].drop_duplicates().values\n",
    ")\n",
    "data_description"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PureSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_from_observations(data, data_description):\n",
    "    useridx = data[data_description['users']]\n",
    "    itemidx = data[data_description['items']]\n",
    "    values = data[data_description['feedback']]\n",
    "    return csr_matrix((values, (useridx, itemidx)), dtype='f8')\n",
    "\n",
    "def build_svd_model(config, data, data_description):\n",
    "    source_matrix = matrix_from_observations(data, data_description)\n",
    "    ... # <- your code here, mind that singular values must be sorted in decreasing order\n",
    "    return item_factors, singular_values\n",
    "\n",
    "def svd_model_scoring(params, data, data_description):\n",
    "    test_matrix = matrix_from_observations(data, data_description)\n",
    "    test_users = data_description['test_users']\n",
    "    item_factors, sigma = params\n",
    "    scores = test_matrix[test_users].dot(item_factors) @ item_factors.T\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_config = {'rank': 40}\n",
    "userid = data_description['users']\n",
    "seen_data = training.loc[lambda x: x[userid].isin(data_description[\"test_users\"])]\n",
    "\n",
    "svd_params = build_svd_model(svd_config, training, data_description)\n",
    "svd_scores = svd_model_scoring(svd_params, seen_data, data_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downvote_seen_items(svd_scores, seen_data, data_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_recs = topn_recommendations(svd_scores, topn=10)\n",
    "model_evaluate(svd_recs, validation, data_description)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3afa3a53b6c5115441aadb460f6d4b1cc743652d4c25bab805986e920f52c789"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('sberrec')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
